---
title: "Predicting Fall Risk Through Foot Tapping  Regression Analysis"
author: "Logan Marshall"
format: pdf
editor: visual
---

**Work on both feet dataset discontinued in Mid-October. Code is not up to date.**

```{r, echo=FALSE, message=FALSE}
library(readxl)

#excel_sheets("DataAllFeatures.xlsx")
dom_df <- read_excel("DataAllFeatures.xlsx", sheet = "Dominant foot")
ndom_df <- read_excel("DataAllFeatures.xlsx", sheet = "Nondominant")
```

##Data Cleaning

```{r, message=FALSE}
library(dplyr)

dom_df <- dom_df %>% select (-`Fall risk level`)

#Participant name in dominant foot data but not in nondominant
extra_ids <- setdiff(dom_df$ParticipantName, ndom_df$ParticipantName)
#Remove them from dom_df
dom_df_clean <- dom_df[!(dom_df$ParticipantName %in% extra_ids), ]

#Vice versa
nextra_ids <- setdiff(ndom_df$ParticipantName, dom_df$ParticipantName)
ndom_df_clean <- ndom_df[!(ndom_df$ParticipantName %in% nextra_ids), ]

df <- merge(dom_df_clean, ndom_df_clean, by = "ParticipantName", suffixes = c("_dom", "_ndom"))

df <- df %>% select(-(ParticipantName:acctime_tkeoMAE_dom))
df <- df %>% select (-acctime_tapsforce_dom)
df <- df %>% select (-(acctime_Rsquaretinsfreqfitted_dom:acctime_MSEexpfitamptap_dom))
df <- df %>% select (-acctime_MSElinearfitamptap_dom)
df <- df %>% select (-gyrotime_numberbumps_dom)
df <- df %>% select (-gyrotimefrequency_numberinteruption_dom)
df <- df %>% select (-gyrotimefrequency_numberfreez_dom)
df <- df %>% select(-(gyrotimefrequency_maxdominantfrequencytime_dom:gyrotimefrequency_interceptdominantfrequency_dom))
df <- df %>% select(-(gyrotimefrequency_longestinteruptcsa30_dom:gyrotimefrequency_csavariability_dom))
df <- df %>% select (-(acctime_Power_1_dom:acctime_Power_4_dom))
df <- df %>% select (-(gyrotime_Power_1_dom:gyrotime_Power_3_dom))

df <- df %>% select(-(TrialName_ndom:acctime_tkeoMAE_ndom))
df <- df %>% select (-acctime_tapsforce_ndom)
df <- df %>% select (-(acctime_Rsquaretinsfreqfitted_ndom:acctime_MSEexpfitamptap_ndom))
df <- df %>% select (-acctime_MSElinearfitamptap_ndom)
df <- df %>% select (-gyrotime_numberbumps_ndom)
df <- df %>% select (-gyrotimefrequency_numberinteruption_ndom)
df <- df %>% select (-gyrotimefrequency_numberfreez_ndom)
df <- df %>% select(-(gyrotimefrequency_maxdominantfrequencytime_ndom:gyrotimefrequency_interceptdominantfrequency_ndom))
df <- df %>% select(-(gyrotimefrequency_longestinteruptcsa30_ndom:gyrotimefrequency_csavariability_ndom))
df <- df %>% select (-(`Gait Time_ndom`:`Age numerical_ndom`))
df <- df %>% select (-(acctime_Power_1_ndom:acctime_Power_4_ndom))
df <- df %>% select (-(gyrotime_Power_1_ndom:gyrotime_Power_3_ndom))

df <- df %>% rename (`Gait Time` = `Gait Time_dom`)
df <- df %>% rename (`TUG Time` = `TUG Time_dom`)
df <- df %>% rename (`Age numerical` = `Age numerical_dom`)
```

## Lasso

### Gait Lasso

```{r, message=FALSE}
library(caret)
set.seed(101)

gait_train_index <- createDataPartition(df$`Gait Time`, p = 0.7, list = FALSE)
gait_train_df <- df[gait_train_index, ]
gait_test_df  <- df[-gait_train_index, ]

names(gait_train_df) <- make.names(names(gait_train_df), unique = TRUE)
names(gait_test_df) <- make.names(names(gait_test_df), unique = TRUE)
```

```{r}
y <- gait_train_df$Gait.Time

x <- model.matrix(Gait.Time ~ . - Gait.Time - TUG.Time, data=gait_train_df)

library(glmnet)
whole_lasso_fit <- glmnet(x,y,alpha=1)

#plot(whole_lasso_fit, xvar="lambda")
set.seed(101)
whole_cv_lasso <- cv.glmnet(x, y, alpha = 1)

#plot(whole_cv_lasso)

#best lambdas
best_lambda <- whole_cv_lasso$lambda.min  #lambda that minimizes CV error/test MSE
best_lambda_1se <- whole_cv_lasso$lambda.1se  #1-SE rule (simpler model)
#best_lambda
#best_lambda_1se

#coef(whole_cv_lasso, s = "lambda.min") #coefficients at best lambda

lasmin <- glmnet(x,y,alpha = 1, lambda=best_lambda)

gait_coef <- coef(lasmin)

#coef(lasmin)
Gait_Las_columns <- rownames(coef(lasmin))[which(coef(lasmin) != 0)]
Gait_Las_columns <- Gait_Las_columns[Gait_Las_columns != "(Intercept)"]

x_test <- model.matrix( ~ . - Gait.Time - TUG.Time, data = gait_test_df)
y_test <- gait_test_df$Gait.Time

y_pred <- predict(lasmin, s = best_lambda, newx = x_test)

rmse_test <- sqrt(mean((y_test - y_pred)^2))
rmse_test

y_train_pred <- predict(lasmin, s = best_lambda, newx = x)

rmse_train <- sqrt(mean((y - y_train_pred)^2))
sst_train <- sum((y - mean(y))^2)
sse_train <- sum((y - y_train_pred)^2)
rsq_train <- 1 - sse_train/sst_train

rsq_train
rmse_train

sst_test <- sum((y_test - mean(y_test))^2)
sse_test <- sum((y_test - y_pred)^2)
rsq_test <- 1 - sse_test/sst_test
rsq_test
```

```{r}
gait_lasreg <- lm(Gait.Time ~ acctime_ITIsd_ndom + acctime_Powerlog_4_ndom + accTimeFrequency_MeanSumenergy_4_dom, data = gait_train_df)
summary(gait_lasreg)

pred_train <- predict(gait_lasreg, newdata = gait_train_df)
rmse_train <- sqrt(mean((gait_train_df$Gait.Time - pred_train)^2))

pred_test <- predict(gait_lasreg, newdata = gait_test_df)
rmse_test <- sqrt(mean((gait_test_df$Gait.Time - pred_test)^2))

rmse_train
rmse_test
```

### Tug Lasso

```{r}
set.seed(101)
tug_train_index <- createDataPartition(df$`TUG Time`, p = 0.7, list = FALSE)
tug_train_df <- df[tug_train_index, ]
tug_test_df  <- df[-tug_train_index, ]

names(tug_train_df) <- make.names(names(tug_train_df), unique = TRUE)
names(tug_test_df) <- make.names(names(tug_test_df), unique = TRUE)
```

```{r}
y <- tug_train_df$TUG.Time

x <- model.matrix(TUG.Time ~ . - Gait.Time - TUG.Time, data=tug_train_df)

whole_lasso_fit <- glmnet(x,y,alpha=1)

#plot(whole_lasso_fit, xvar="lambda")

set.seed(101)
whole_cv_lasso <- cv.glmnet(x, y, alpha = 1)

#plot(whole_cv_lasso)

#best lambdas
best_lambda <- whole_cv_lasso$lambda.min       #λ that minimizes CV error
best_lambda_1se <- whole_cv_lasso$lambda.1se   #1-SE rule (simpler model)
#best_lambda
#best_lambda_1se

#coef(whole_cv_lasso, s = "lambda.min")   #coefficients at best λ
lasmin <- glmnet(x,y,alpha = 1, lambda=best_lambda)

tug_coef <- coef(lasmin)
#coef(lasmin)
Tug_Las_columns <- rownames(tug_coef)[which(tug_coef != 0)]
Tug_Las_columns <- Tug_Las_columns[Tug_Las_columns != "(Intercept)"]

x_test <- model.matrix(TUG.Time ~ . - Gait.Time - TUG.Time,, data = tug_test_df)
y_test <- tug_test_df$TUG.Time

y_pred <- predict(lasmin, s = best_lambda, newx = x_test)

rmse_test <- sqrt(mean((y_test - y_pred)^2))
rmse_test

y_train_pred <- predict(lasmin, s = best_lambda, newx = x)

rmse_train <- sqrt(mean((y - y_train_pred)^2))
sst_train <- sum((y - mean(y))^2)
sse_train <- sum((y - y_train_pred)^2)
rsq_train <- 1 - sse_train/sst_train

rmse_train
rsq_train
```

##Stepwise

##Gait Step

### Forward Selection

```{r}
corr_matrix <- cor(gait_train_df[ , !(names(gait_train_df) %in% c("TUG.Time", "Gait.Time"))])
high_corr <- findCorrelation(corr_matrix, cutoff = 0.6)

predictor_names <- names(gait_train_df)[!(names(gait_train_df) %in% c("TUG.Time", "Gait.Time"))]
reduced_predictors <- predictor_names[-high_corr]

reduced_train <- gait_train_df[, c("Gait.Time", reduced_predictors)]

full_gait <- lm(Gait.Time ~ ., data = reduced_train)
model.empty <- lm(Gait.Time~1, data=reduced_train) #Intercept only
forward_gait <- step(model.empty,direction = "forward",
                       scope = list(lower = model.empty, upper = full_gait)) #AIC
summary(forward_gait)

reduced_test <- gait_test_df[, c("Gait.Time", reduced_predictors)]

test_preds <- predict(forward_gait, newdata = reduced_test)

y_true <- reduced_test$Gait.Time

rmse_test <- sqrt(mean((y_true - test_preds)^2))
rmse_test

train_preds <- predict(forward_gait, newdata = reduced_train)

y_train <- reduced_train$Gait.Time

rmse_train <- sqrt(mean((y_train - train_preds)^2))
rmse_train

sse <- sum((y_true - test_preds)^2)
sst <- sum((y_true - mean(y_true))^2)
test_r2 <- 1 - sse/sst
test_r2
```

### Mixed

```{r}
mixed_gait <- step(model.empty,direction = "both", scope = list(lower = model.empty, upper = full_gait))
summary(mixed_gait)

test_preds <- predict(mixed_gait, newdata = reduced_test)

y_true <- reduced_test$Gait.Time

rmse_test <- sqrt(mean((y_true - test_preds)^2))
rmse_test

train_preds <- predict(mixed_gait, newdata = reduced_train)
y_train <- reduced_train$Gait.Time
rmse_train <- sqrt(mean((y_train - train_preds)^2))
rmse_train

sse <- sum((y_true - test_preds)^2)
sst <- sum((y_true - mean(y_true))^2)
test_r2 <- 1 - sse/sst
test_r2
```

##Tug Step

### Forward Selection

```{r}
corr_matrix <- cor(tug_train_df[ , !(names(tug_train_df) %in% c("TUG.Time", "Gait.Time"))])
high_corr <- findCorrelation(corr_matrix, cutoff = 0.55)

predictor_names <- names(tug_train_df)[!(names(tug_train_df) %in% c("TUG.Time", "Gait.Time"))]
reduced_predictors <- predictor_names[-high_corr]

reduced_train <- tug_train_df[, c("TUG.Time", reduced_predictors)]

full_tug <- lm(TUG.Time ~ ., data = reduced_train)

model.empty <- lm(TUG.Time~1, data=reduced_train) #Intercept only
forward_tug <- step(model.empty,direction = "forward",
                       scope = list(lower = model.empty, upper = full_tug)) #AIC
summary(forward_tug)

reduced_test <- tug_test_df[, c("TUG.Time", reduced_predictors)] #Code line not needed
test_preds <- predict(forward_tug, newdata = reduced_test)

y_true <- reduced_test$TUG.Time

rmse_test <- sqrt(mean((y_true - test_preds)^2))
rmse_test

train_preds <- predict(forward_tug, newdata = reduced_train)
y_train <- reduced_train$TUG.Time
rmse_train <- sqrt(mean((y_train - train_preds)^2))
rmse_train
```

### Mixed

```{r}
mixed_tug <- step(model.empty,direction = "both", scope = list(lower = model.empty, upper = full_tug))
summary(mixed_tug)

test_preds <- predict(mixed_tug, newdata = reduced_test)

y_true <- reduced_test$TUG.Time

rmse_test <- sqrt(mean((y_true - test_preds)^2))
rmse_test
train_preds <- predict(mixed_tug, newdata = reduced_train)
y_train <- reduced_train$TUG.Time
rmse_train <- sqrt(mean((y_train - train_preds)^2))
rmse_train
```

##Ridge

### Gait Ridge

```{r}
y <- gait_train_df$Gait.Time

x <- model.matrix( ~ . - Gait.Time - TUG.Time, data=gait_train_df)

whole_lasso_fit <- glmnet(x,y,alpha=0)

#plot(whole_lasso_fit, xvar="lambda")
set.seed(101)
whole_cv_lasso <- cv.glmnet(x, y, alpha = 0)

#plot(whole_cv_lasso)

#best lambdas
best_lambda <- whole_cv_lasso$lambda.min  #lambda that minimizes CV error/test MSE
best_lambda_1se <- whole_cv_lasso$lambda.1se  #1-SE rule (simpler model)
#best_lambda
#best_lambda_1se

lasmin <- glmnet(x,y,alpha = 0, lambda=best_lambda)

x_test <- model.matrix( ~ . - Gait.Time - TUG.Time, data = gait_test_df)
y_test <- gait_test_df$Gait.Time

y_pred <- predict(lasmin, s = best_lambda, newx = x_test)

rmse_test <- sqrt(mean((y_test - y_pred)^2))
rmse_test

y_train_pred <- predict(lasmin, s = best_lambda, newx = x)

rmse_train <- sqrt(mean((y - y_train_pred)^2))
sst_train <- sum((y - mean(y))^2)
sse_train <- sum((y - y_train_pred)^2)
rsq_train <- 1 - sse_train/sst_train

rmse_train
rsq_train
```

### Tug Ridge

```{r}
y <- tug_train_df$TUG.Time

x <- model.matrix(TUG.Time ~ . - Gait.Time - TUG.Time, data=tug_train_df)

whole_lasso_fit <- glmnet(x,y,alpha=0)

#plot(whole_lasso_fit, xvar="lambda")
set.seed(101)
whole_cv_lasso <- cv.glmnet(x, y, alpha = 0)

#plot(whole_cv_lasso)

#best lambdas
best_lambda <- whole_cv_lasso$lambda.min       #λ that minimizes CV error
best_lambda_1se <- whole_cv_lasso$lambda.1se   #1-SE rule (simpler model)
#best_lambda
#best_lambda_1se

#coef(whole_cv_lasso, s = "lambda.min")   #coefficients at best λ
lasmin <- glmnet(x,y,alpha = 0, lambda=best_lambda)

Tug_ridge_columns <- rownames(coef(lasmin))[which(coef(lasmin) != 0)]
Tug_ridge_columns <- Tug_ridge_columns[Tug_ridge_columns != "(Intercept)"]

#coef(lasmin)

x_test <- model.matrix(TUG.Time ~ . - Gait.Time - TUG.Time, data = tug_test_df)
y_test <- tug_test_df$TUG.Time

y_pred <- predict(lasmin, s = best_lambda, newx = x_test)

rmse_test <- sqrt(mean((y_test - y_pred)^2))
rmse_test

y_train_pred <- predict(lasmin, s = best_lambda, newx = x)

rmse_train <- sqrt(mean((y - y_train_pred)^2))
sst_train <- sum((y - mean(y))^2)
sse_train <- sum((y - y_train_pred)^2)
rsq_train <- 1 - sse_train/sst_train

rmse_train
rsq_train
```

## Ensemble Methods

### Gait Forest

```{r, fig.width=10, fig.height=8}
#gaitRF <- randomForest(
#  `Gait Time` ~ .,
#  data = subset(gait_train_df, select = -`TUG Time`),  #remove the other response variable
#  mtry = sqrt(ncol(gait_train_df) - 2),  #total predictors minus response and excluded var
#  importance = TRUE
#)

#formula_terms <- attr(terms(`Gait Time` ~ ., data=gait_train_df), "term.labels")
#data_terms <- setdiff(names(subset(gait_train_df, select = -`TUG Time`)), "Gait Time")

#setdiff(formula_terms, data_terms)

library(randomForest)
set.seed(101)
gaitRF <- randomForest(
  Gait.Time ~ .,
  data = subset(gait_train_df, select = -TUG.Time), #remove the other response variable
  mtry = (ncol(gait_train_df) - 2)/3, #total predictors minus response and excluded var
  #ntree=200, #error plot (OOB error vs. number of trees) shows that the preformance stablizes at 200. Not really needed, therefore I commented it out.
  importance = TRUE
)
gaitRF

gaitRF_pred <- predict(gaitRF, newdata = subset(gait_test_df, select = -c(Gait.Time, TUG.Time)))

gaitRF_true <- gait_test_df$Gait.Time

rmse_test <- sqrt(mean((gaitRF_pred - gaitRF_true)^2))

rmse_test

varImpPlot(gaitRF, n.var = 10, main = "Top 10 Variable Importances")

importance_vals <- importance(gaitRF)

#Convert to data frame for easier sorting
importance_df <- data.frame(
  Feature = rownames(importance_vals),
  importance_vals
)

top10 <- importance_df[order(-importance_df$X.IncMSE), ][1:10, ]
print(top10)
```

### Gait Bagging

```{r}
gaitBag <- randomForest(
  Gait.Time ~ .,
  data = subset(gait_train_df, select = -TUG.Time), #remove the other response variable
  mtry = (ncol(gait_train_df) - 2), #total predictors minus response and excluded var
  importance = TRUE
)
gaitBag

gaitBag_pred <- predict(gaitBag, newdata = subset(gait_test_df, select = -c(Gait.Time, TUG.Time)))

gaitBag_true <- gait_test_df$Gait.Time

rmse_test <- sqrt(mean((gaitBag_pred - gaitBag_true)^2))

rmse_test
```

### Gait Boosting

```{r}
library(gbm)
set.seed(101)
gaitgbm <- gbm(Gait.Time ~ .,
  data = subset(gait_train_df, select = -TUG.Time), #remove the other response variable
  distribution = "gaussian",
  n.trees = 5000, 
  interaction.depth = 1,
  shrinkage = 0.01,
  cv.folds = 5)

summary(gaitgbm)

best_iter <- gbm.perf(gaitgbm, method = "cv")
best_iter

train_pred <- predict(gaitgbm, newdata = subset(gait_train_df, select = -c(Gait.Time, TUG.Time)), n.trees = best_iter)
test_pred  <- predict(gaitgbm, newdata = subset(gait_test_df, select = -c(Gait.Time, TUG.Time)), n.trees = best_iter)

rmse_train <- sqrt(mean((train_pred - gait_train_df$Gait.Time)^2))
rmse_test  <- sqrt(mean((test_pred  - gait_test_df$Gait.Time)^2))

r2_train <- 1 - sum((gait_train_df$Gait.Time - train_pred)^2) / sum((gait_train_df$Gait.Time - mean(gait_train_df$Gait.Time))^2)
r2_test  <- 1 - sum((gait_test_df$Gait.Time - test_pred)^2) / sum((gait_test_df$Gait.Time - mean(gait_test_df$Gait.Time))^2)

rmse_train; rmse_test
r2_train
```

### Tug Forest

```{r, fig.width=10, fig.height=8}
set.seed(101)
tugRF <- randomForest(
  TUG.Time ~ .,
  data = subset(tug_train_df, select = -Gait.Time), #remove the other response variable
  mtry = (ncol(tug_train_df) - 2)/3, #total predictors minus response and excluded var
  #ntree = 200,
  importance = TRUE
)
tugRF

tugRF_pred <- predict(tugRF, newdata = subset(tug_test_df, select = -c(Gait.Time, TUG.Time)))

tugRF_true <- tug_test_df$TUG.Time

rmse_test <- sqrt(mean((tugRF_pred - tugRF_true)^2))

rmse_test

varImpPlot(tugRF, n.var = 10, main = "Top 10 Variable Importances")
```

### Tug Bagging

```{r}
set.seed(101)
tugBag <- randomForest(
  TUG.Time ~ .,
  data = subset(tug_train_df, select = -Gait.Time), #remove the other response variable
  mtry = (ncol(tug_train_df) - 2)/3, #total predictors minus response and excluded var
  importance = TRUE
)
tugBag

tugBag_pred <- predict(tugBag, newdata = subset(tug_test_df, select = -c(Gait.Time, TUG.Time)))

tugBag_true <- tug_test_df$TUG.Time

rmse_test <- sqrt(mean((tugBag_pred - tugBag_true)^2))

rmse_test
```

### Tug Boosting

```{r}
set.seed(101)
tuggbm <- gbm(TUG.Time ~ .,
  data = subset(tug_train_df, select = -Gait.Time), #remove the other response variable
  distribution = "gaussian",
  n.trees = 5000, 
  interaction.depth = 1,
  shrinkage = 0.01,
  cv.folds = 5)

#summary(tuggbm)

best_iter <- gbm.perf(tuggbm, method = "cv")
#best_iter

train_pred <- predict(tuggbm, newdata = subset(tug_train_df, select = -c(Gait.Time, TUG.Time)), n.trees = best_iter)
test_pred  <- predict(tuggbm, newdata = subset(tug_test_df, select = -c(Gait.Time, TUG.Time)), n.trees = best_iter)

rmse_train <- sqrt(mean((train_pred - tug_train_df$TUG.Time)^2))
rmse_test  <- sqrt(mean((test_pred  - tug_test_df$TUG.Time)^2))

r2_train <- 1 - sum((tug_train_df$TUG.Time - train_pred)^2) / sum((tug_train_df$TUG.Time - mean(tug_train_df$TUG.Time))^2)
r2_test  <- 1 - sum((tug_test_df$TUG.Time - test_pred)^2) / sum((tug_test_df$TUG.Time - mean(tug_test_df$TUG.Time))^2)

rmse_train; rmse_test
r2_train
```

## Support Vector Machines

### Gait SVM

```{r}
library(e1071)
library(kernlab)
set.seed(101)

names(gait_train_df) <- make.names(names(gait_train_df), unique = TRUE)
names(gait_test_df) <- make.names(names(gait_test_df), unique = TRUE)

x_train <- gait_train_df[, !(names(gait_train_df) %in% c("Gait.Time", "TUG.Time"))]
y_train <- gait_train_df$Gait.Time

x_test <- gait_test_df[, !(names(gait_test_df) %in% c("Gait.Time", "TUG.Time"))]
y_test <- gait_test_df$Gait.Time

set.seed(101)
#Define train control for 10-fold cross-validation
train_control <- trainControl(method = "cv", number = 10)

#Tuning grid for radial kernels
svm_grid <- expand.grid(
  sigma = c(0.001, 0.01, 0.1),      #used only for RBF
  C = c(0.01, 0.1, 1, 10)         #cost parameter
)

x_train <- as.data.frame(x_train)
x_test  <- as.data.frame(x_test)

#Training SVM with radial basis function kernel
svm_tuned <- train(
  x = x_train,
  y = y_train,
  method = "svmRadial",           
  tuneGrid = svm_grid,
  trControl = train_control,
  preProcess = c("center", "scale")
)
#print(svm_tuned)
#svm_tuned$finalModel

y_train_pred <- predict(svm_tuned, newdata = x_train)
y_test_pred  <- predict(svm_tuned, newdata = x_test)

rmse_train <- sqrt(mean((y_train - y_train_pred)^2))
rmse_test  <- sqrt(mean((y_test - y_test_pred)^2))

rsq_train <- 1 - sum((y_train - y_train_pred)^2) / sum((y_train - mean(y_train))^2)
rsq_test  <- 1 - sum((y_test - y_test_pred)^2) / sum((y_test - mean(y_test))^2)

rmse_train; rmse_test
rsq_train; rsq_test
```

### Tug SVM

```{r}
set.seed(101)
tug_train_index <- createDataPartition(df$`TUG Time`, p = 0.7, list = FALSE)
tug_train_df <- df[tug_train_index, ]
tug_test_df  <- df[-tug_train_index, ]

names(tug_train_df) <- make.names(names(tug_train_df), unique = TRUE)
names(tug_test_df) <- make.names(names(tug_test_df), unique = TRUE)

x_train <- tug_train_df[, !(names(tug_train_df) %in% c("Gait.Time", "TUG.Time"))]
y_train <- tug_train_df$TUG.Time

x_test <- tug_test_df[, !(names(tug_test_df) %in% c("Gait.Time", "TUG.Time"))]
y_test <- tug_test_df$TUG.Time

set.seed(101)
train_control <- trainControl(method = "cv", number = 10)

svm_grid <- expand.grid(
  sigma = c(0.001, 0.01, 0.1),    
  C = c(0.01, 0.1, 1, 10)         
)

x_train <- as.data.frame(x_train)
x_test  <- as.data.frame(x_test)

svm_tuned <- train(
  x = x_train,
  y = y_train,
  method = "svmRadial",           
  tuneGrid = svm_grid,
  trControl = train_control,
  preProcess = c("center", "scale")
)
#print(svm_tuned)
#svm_tuned$finalModel

y_train_pred <- predict(svm_tuned, newdata = x_train)
y_test_pred  <- predict(svm_tuned, newdata = x_test)

rmse_train <- sqrt(mean((y_train - y_train_pred)^2))
rmse_test  <- sqrt(mean((y_test - y_test_pred)^2))

rsq_train <- 1 - sum((y_train - y_train_pred)^2) / sum((y_train - mean(y_train))^2)
rsq_test  <- 1 - sum((y_test - y_test_pred)^2) / sum((y_test - mean(y_test))^2)

rmse_train; rmse_test
rsq_train; rsq_test
```

## Elastic Net

### Gait Elastic

```{r}
#parameters
alphas <- seq(0, 1, 0.1)
n_iter <- 100

new_df <- df
names(new_df) <- make.names(names(new_df), unique = TRUE)
# build one model matrix from full df to capture correct predictor names
x_all <- model.matrix(Gait.Time ~ . - Gait.Time - TUG.Time, data=new_df)[,-1]   # drop intercept
colnames_x <- colnames(x_all)

#remove columns corresponding to response vars if they slipped in
colnames_x <- colnames_x[!colnames_x %in% c("Gait.Time", "TUG.Time")]

# storage for feature selection counts
feature_counts <- matrix(0, nrow = length(colnames_x), ncol = length(alphas))
colnames(feature_counts) <- paste0("alpha_", alphas)
rownames(feature_counts) <- colnames_x

mse_results  <- matrix(NA, nrow = n_iter, ncol = length(alphas))
rmse_results <- matrix(NA, nrow = n_iter, ncol = length(alphas))
rsq_results  <- matrix(NA, nrow = n_iter, ncol = length(alphas))

colnames(mse_results)  <- paste0("alpha_", alphas)
colnames(rmse_results) <- paste0("alpha_", alphas)
colnames(rsq_results)  <- paste0("alpha_", alphas)

for (i in 1:n_iter) {
  
  # random 70/30 split
  gait_train_index <- createDataPartition(new_df$Gait.Time, p = 0.7, list = FALSE)
  gait_train_df <- new_df[gait_train_index, ]
  gait_test_df  <- new_df[-gait_train_index, ]
  
  #names(gait_train_df) <- make.names(names(gait_train_df), unique = TRUE)
  #names(gait_test_df) <- make.names(names(gait_test_df), unique = TRUE)
  
  y_train <- gait_train_df$Gait.Time
  x_train <- model.matrix(Gait.Time ~ . - Gait.Time - TUG.Time, data = gait_train_df)
  
  y_test <- gait_test_df$Gait.Time
  x_test <- model.matrix(Gait.Time ~ . - Gait.Time - TUG.Time, data = gait_test_df)
  
  for (a in seq_along(alphas)) {
    alpha_val <- alphas[a]
    
    #cross-validation for best lambda
    cv_fit <- cv.glmnet(x_train, y_train, alpha = alpha_val, nfolds = 10)
    best_lambda <- cv_fit$lambda.min
    
    final_fit <- glmnet(x_train, y_train, alpha = alpha_val, lambda = best_lambda)
    
    y_pred <- predict(final_fit, s = best_lambda, newx = x_test)
    
    mse <- mean((y_test - y_pred)^2)
    rmse <- sqrt(mse)
    rsq <- 1 - sum((y_test - y_pred)^2) / sum((y_test - mean(y_test))^2)
    
    mse_results[i, a]  <- mse
    rmse_results[i, a] <- rmse
    rsq_results[i, a]  <- rsq
    
    #track selected features (aka. nonzero coefficients)
    coefs <- coef(final_fit)
    selected <- rownames(coefs)[which(coefs != 0)]
    selected <- selected[selected != "(Intercept)"]
    feature_counts[selected, a] <- feature_counts[selected, a] + 1
  }
}

#aggregate results across iterations
avg_mse  <- colMeans(mse_results,  na.rm = TRUE)
avg_rmse <- colMeans(rmse_results, na.rm = TRUE)
avg_rsq  <- colMeans(rsq_results,  na.rm = TRUE)

best_alpha <- alphas[which.min(avg_mse)]

cat("Best alpha:", best_alpha, "\n\n")
cat("Average MSE:\n");  print(avg_mse)
cat("\nAverage RMSE:\n"); print(avg_rmse)
cat("\nAverage R-squared:\n"); print(avg_rsq)

#top 10 most frequently selected features at best alpha
selected_freq <- feature_counts[, paste0("alpha_", best_alpha)]
top_features <- sort(selected_freq, decreasing = TRUE)[1:10]

cat("\nTop 10 selected features:\n")
print(top_features)
#Best Alpha 0

#AI assisted with format and errors while creating this nested for loop.
```

```{r}
set.seed(101)
gait_train_index <- createDataPartition(new_df$Gait.Time, p = 0.7, list = FALSE)
gait_train_df <- new_df[gait_train_index, ]
gait_test_df  <- new_df[-gait_train_index, ]

y <- gait_train_df$Gait.Time

x <- model.matrix(Gait.Time ~ . - Gait.Time - TUG.Time, data=gait_train_df)

whole_lasso_fit <- glmnet(x,y,alpha=0.1)

#plot(whole_lasso_fit, xvar="lambda")
set.seed(101)
whole_cv_lasso <- cv.glmnet(x, y, alpha =0.1)

#plot(whole_cv_lasso)

#best lambdas
best_lambda <- whole_cv_lasso$lambda.min  #lambda that minimizes CV error/test MSE
best_lambda_1se <- whole_cv_lasso$lambda.1se  #1-SE rule (simpler model)
#best_lambda
#best_lambda_1se

#coef(whole_cv_lasso, s = "lambda.min") #coefficients at best lambda

lasmin <- glmnet(x,y,alpha = 0.1, lambda=best_lambda)

#coef(lasmin)
Gait_ela_columns <- rownames(coef(lasmin))[which(coef(lasmin) != 0)]
Gait_ela_columns <- Gait_ela_columns[Gait_ela_columns != "(Intercept)"]

x_test <- model.matrix(Gait.Time ~ . - Gait.Time - TUG.Time, data = gait_test_df)
y_test <- gait_test_df$Gait.Time

y_pred <- predict(lasmin, s = best_lambda, newx = x_test)

rmse_test <- sqrt(mean((y_test - y_pred)^2))
rmse_test

y_train_pred <- predict(lasmin, s = best_lambda, newx = x)

rmse_train <- sqrt(mean((y - y_train_pred)^2))
sst_train <- sum((y - mean(y))^2)
sse_train <- sum((y - y_train_pred)^2)
rsq_train <- 1 - sse_train/sst_train

rsq_train
rmse_train
```

### Tug Elastic

```{r}
#parameters
alphas <- seq(0, 1, 0.1)
n_iter <- 100

# build one model matrix from full df to capture correct predictor names
x_all <- model.matrix(TUG.Time ~ . - Gait.Time - TUG.Time, data=new_df)[,-1]   # drop intercept
colnames_x <- colnames(x_all)

# remove dummy columns corresponding to response vars if they slipped in
colnames_x <- colnames_x[!colnames_x %in% c("Gait.Time", "TUG.Time")]

# storage for feature selection counts
feature_counts <- matrix(0, nrow = length(colnames_x), ncol = length(alphas))
colnames(feature_counts) <- paste0("alpha_", alphas)
rownames(feature_counts) <- colnames_x

mse_results  <- matrix(NA, nrow = n_iter, ncol = length(alphas))
rmse_results <- matrix(NA, nrow = n_iter, ncol = length(alphas))
rsq_results  <- matrix(NA, nrow = n_iter, ncol = length(alphas))

colnames(mse_results)  <- paste0("alpha_", alphas)
colnames(rmse_results) <- paste0("alpha_", alphas)
colnames(rsq_results)  <- paste0("alpha_", alphas)

for (i in 1:n_iter) {
  
  # random 70/30 split
  tug_train_index <- createDataPartition(new_df$TUG.Time, p = 0.7, list = FALSE)
  tug_train_df <- new_df[tug_train_index, ]
  tug_test_df  <- new_df[-tug_train_index, ]
  
  y_train <- tug_train_df$TUG.Time
  x_train <- model.matrix(TUG.Time ~ . - Gait.Time - TUG.Time, data = tug_train_df)
  
  y_test <- tug_test_df$TUG.Time
  x_test <- model.matrix(TUG.Time ~ . - Gait.Time - TUG.Time, data = tug_test_df)
  
  for (a in seq_along(alphas)) {
    alpha_val <- alphas[a]
    
    cv_fit <- cv.glmnet(x_train, y_train, alpha = alpha_val, nfolds = 10)
    best_lambda <- cv_fit$lambda.min
    
    final_fit <- glmnet(x_train, y_train, alpha = alpha_val, lambda = best_lambda)
    
    y_pred <- predict(final_fit, s = best_lambda, newx = x_test)
    
    mse <- mean((y_test - y_pred)^2)
    rmse <- sqrt(mse)
    rsq <- 1 - sum((y_test - y_pred)^2) / sum((y_test - mean(y_test))^2)
    
    mse_results[i, a]  <- mse
    rmse_results[i, a] <- rmse
    rsq_results[i, a]  <- rsq
    
    coefs <- coef(final_fit)
    selected <- rownames(coefs)[which(coefs != 0)]
    selected <- selected[selected != "(Intercept)"]
    feature_counts[selected, a] <- feature_counts[selected, a] + 1
  }
}

avg_mse  <- colMeans(mse_results,  na.rm = TRUE)
avg_rmse <- colMeans(rmse_results, na.rm = TRUE)
avg_rsq  <- colMeans(rsq_results,  na.rm = TRUE)

best_alpha <- alphas[which.min(avg_mse)]

cat("Best alpha:", best_alpha, "\n\n")
cat("Average MSE:\n");  print(avg_mse)
cat("\nAverage RMSE:\n"); print(avg_rmse)
cat("\nAverage R-squared:\n"); print(avg_rsq)

#top 10 most frequently selected features at best alpha
selected_freq <- feature_counts[, paste0("alpha_", best_alpha)]
top_features <- sort(selected_freq, decreasing = TRUE)[1:10]

cat("\nTop 10 selected features:\n")
print(top_features)

```

```{r}
set.seed(101)
tug_train_index <- createDataPartition(new_df$TUG.Time, p = 0.7, list = FALSE)
tug_train_df <- new_df[tug_train_index, ]
tug_test_df  <- new_df[-tug_train_index, ]

y <- tug_train_df$TUG.Time

x <- model.matrix(TUG.Time ~ . - Gait.Time - TUG.Time, data=tug_train_df)

whole_lasso_fit <- glmnet(x,y,alpha=0.1)

#plot(whole_lasso_fit, xvar="lambda")

set.seed(101)
whole_cv_lasso <- cv.glmnet(x, y, alpha = 0.1)

#plot(whole_cv_lasso)

#best lambdas
best_lambda <- whole_cv_lasso$lambda.min       #λ that minimizes CV error
best_lambda_1se <- whole_cv_lasso$lambda.1se   #1-SE rule (simpler model)
#best_lambda
#best_lambda_1se

#coef(whole_cv_lasso, s = "lambda.min")   #coefficients at best λ
lasmin <- glmnet(x,y,alpha = 0.1, lambda=best_lambda)

#tug_coef <- coef(lasmin)
#coef(lasmin)
Tug_ela_columns <- rownames(coef(lasmin))[which(coef(lasmin) != 0)]
Tug_ela_columns <- Tug_ela_columns[Tug_ela_columns != "(Intercept)"]

x_test <- model.matrix(TUG.Time ~ . - Gait.Time - TUG.Time, data = tug_test_df)
y_test <- tug_test_df$TUG.Time

y_pred <- predict(lasmin, s = best_lambda, newx = x_test)

rmse_test <- sqrt(mean((y_test - y_pred)^2))
rmse_test

y_train_pred <- predict(lasmin, s = best_lambda, newx = x)

rmse_train <- sqrt(mean((y - y_train_pred)^2))
sst_train <- sum((y - mean(y))^2)
sse_train <- sum((y - y_train_pred)^2)
rsq_train <- 1 - sse_train/sst_train

rmse_train
rsq_train
```
